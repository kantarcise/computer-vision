{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In the last video, we talked about analog and digital cameras and discovered modern camera systems in phones.\n",
    "\n",
    "Today we will try to establish the intersection between computer vision and the history behind research on how vision is formed in the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubel and Wiesel üê±\n",
    "\n",
    "The [link to the Paper (from 1959).](https://physoc.onlinelibrary.wiley.com/doi/epdf/10.1113/jphysiol.1959.sp006308) \n",
    "\n",
    "Here is a short video called, [The Cat Experiment.](https://www.youtube.com/watch?v=IOHayh06LJ4)\n",
    "\n",
    "In 1959, David Hubel and Torsten Wiesel provided a quantum step in our understanding of the visual system.\n",
    "\n",
    "Their work was about the complex mechanisms involved in transforming simple information from the eyes into our rich and complete visual perception of the world.\n",
    "\n",
    "They won Nobel Prize in 1981.\n",
    "\n",
    "![Hubel and Wiesel](../img/hubel_wiesel/Hubel-and-Wiesel.jpg)\n",
    "\n",
    "[Source](https://www.brains-explained.com/how-hubel-and-wiesel-revolutionized-neuroscience/)\n",
    "\n",
    "At the time, Hubel and Wiesel were unaware of photoreceptors, but earlier research had revealed that the output neurons of the retina, responsible for transmitting visual information from the eyes to the brain, exhibit relatively simple responses to light.\n",
    "\n",
    "But simple responses to light was obviously not enough to explain our visual system.\n",
    "\n",
    "They were trying to understand how vision really happened in brain. They were trying to understand the secrets of visual cortex.\n",
    "\n",
    "![Visual Cortex](../img/hubel_wiesel/visualCortex.png)\n",
    "\n",
    "[Source](https://hive.blog/hive-196387/@nattybongo/brain-areas-for-sight)\n",
    "\n",
    "The **visual cortex**, located in the occipital lobe of the brain, is primarily responsible for interpreting and processing visual information received from the eyes, specialized for various aspects of visual processing, including object recognition, spatial localization, and motion detection.\n",
    "\n",
    "They actually made the **beginning for the knowledge of a deep learning model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did it all happen? ü§î\n",
    "\n",
    "They used electrodes to monitor the activity on a brain of a cat, and they were trying to understand what makes neurons fire in vision.\n",
    "\n",
    "_\"When we started working in the late 50s we set up her first experiments and they didn't go well._\n",
    "\n",
    "They tried all kinds of objects from magazines, fish, mouse and flower pictures. Nothing seem to work.\n",
    "\n",
    "_Because at the beginning we couldn't make the cells fire at all we'd shine lights all over the screen and nothing seemed to work. Rather by accident one day we were shining small spots either white spots or black spots onto the screen._\n",
    "\n",
    "_We found that the black dot seemed to be working in a way that at first we couldn't understand until we found that it was the process of slipping the piece of glass into the projector which swept a lie a very faint precise narrow line across the retina._\n",
    "\n",
    "_And every time we did that we'd get a response\"_\n",
    "\n",
    "![experiment](../img/hubel_wiesel/hubel_wiesel_the_hierarchy.png)\n",
    "\n",
    "[Source](https://youtu.be/NfnWJUyUJYU?t=1600)\n",
    "\n",
    "So sliding a piece of glass and making an edge (without even meaning it) cause the neurons to fire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Findings](../img/hubel_wiesel/hubel_wiesel_findings.png)\n",
    "\n",
    "### Here are the findings: üîé\n",
    "\n",
    "- In **particular orientation**, neurons get excited about edges.\n",
    "\n",
    "- Nearby cells in the visual cortex are processing nearby areas in your visual field. **Locality** is preserved in processing.\n",
    "\n",
    "- Visual cortex has a hierarchical organization. Simple cells to complex cells through layers.\n",
    "\n",
    "![Featural Hierarchy](../img/hubel_wiesel/hubel_wiesel_hierarchy.png)\n",
    "\n",
    "\n",
    "Recommended Reads:\n",
    "\n",
    "[How Hubel and Wiesel Revolutionized Neuroscience and Made Me a Neuroscientist](https://www.brains-explained.com/how-hubel-and-wiesel-revolutionized-neuroscience/)\n",
    "\n",
    "[Recounting the impact of Hubel and Wiesel](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2718241/)\n",
    "\n",
    "[THE PRIMARY VISUAL CORTEX BY MATTHEW SCHMOLESKY](https://webvision.med.utah.edu/book/part-ix-brain-visual-areas/the-primary-visual-cortex/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To learn more about Perception üëÄ\n",
    "\n",
    "Here is a wonderful link about [human perception.](https://www.cns.nyu.edu/~david/courses/perception/lecturenotes/V1/lgn-V1.html)\n",
    "\n",
    "_David Hubel and Torsten Wiesel won the Nobel prize for discovering the functional organization and basic physiology of neurons in V1 (V1 = Primary Visual Cortex)._ \n",
    "\n",
    "_They discovered three different types of neurons that can be distinguished based on how they respond to visual stimuli that they called: **simple cells**, **complex cells**, and **hypercomplex cells.**_ \n",
    "\n",
    "**Orientation selectivity**: Most V1 neurons are orientation selective meaning that they respond strongly to lines, bars, or edges of a particular orientation (e.g., vertical) but not to the orthogonal orientation (e.g., horizontal).\n",
    "\n",
    "**Direction selectivity**: Some V1 cells are also direction selective meaning that they respond strongly to oriented lines/bars/edges moving in a preferred direction (e.g., vertical lines moving to the right) but not at all in the opposite direction (e.g., vertical lines moving to the left).\n",
    "\n",
    "![Direction Selectivity](../img/hubel_wiesel/hubel_wiesel_direction_selectivity.jpg)\n",
    "\n",
    "**V1 functional architecture**: Hubel and Wiesel also discovered that the neurons in V1 are arranged in an orderly fashion. \n",
    "\n",
    "Neurons with similar response properties (e.g., the same orientation preference) lie nearby one another.\n",
    "\n",
    "**Columnar architecture**: As one moves an electrode vertically through the thickness of cortex, one finds that most neurons have the same selectivity (e.g., the same orientation preference and eye dominance). \n",
    "\n",
    "**Ocular dominance columns**: As one moves an electrode tangentially through the cortex, one first finds cells that respond to left eye inputs, then binocular (responsive to both/either eye), then right eye, then binocular, then left again, etc. \n",
    "\n",
    "**Orientation columns**: As one moves the electrode tangentially in the orthogonal direction, one first find cells selective for vertical, then diagonal, then horizontal, etc.\n",
    "\n",
    "A hypercolumn is a chunk of cortex about 1 mm square by 3 mm thick that contains neurons, all with approximately the same receptive field location, but with all different orientation selectivities, direction selectivities, both (left- and right-) eye dominances represented.\n",
    "\n",
    "![Columnar architecture](../img/hubel_wiesel/hubel_wiesel_columnar_architecture.jpg)\n",
    "\n",
    "Also in this [MIT Course - 9.11: The Human Brain ](https://www.youtube.com/watch?v=ePP0G7FJGPI) you can learn about more for these findings.\n",
    "\n",
    "[Here is the book from Hubel and Wiesel](https://books.google.co.in/books?id=8YrxWojxUA4C&lpg=PA106&pg=PA104#v=onepage&q&f=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIT Summer Vision Project ‚òÄÔ∏è\n",
    "\n",
    "This event is considered the birthday of computer vision - Summer of 1966.\n",
    "\n",
    "_\"Vision is so easy!\"_\n",
    "\n",
    "However, Computer Vision is not solved in that Summer.\n",
    "\n",
    "![Summer Vision](../img/hubel_wiesel/MIT_summer_vision.png)\n",
    "\n",
    "In 1966, Seymour Papert, an MIT professor working at the AI lab, set out on an ambitious venture known as the Summer Vision Project. He aimed to address the challenge of machine vision and achieve a solution within a short span of a few months.\n",
    "\n",
    "He encouraged the students to develop a significant component of a visual system in one summer. The students tried to create a platform capable of automatically differentiating between the foreground and background in images, as well as extracting distinct objects without any overlapping, all from real-world scenes.\n",
    "\n",
    "Although the Summer Vision Project did not yield the desired success, it holds immense significance in the history of computer vision. Many regard it as the official birth of computer vision as a scientific field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## David Marr\n",
    "\n",
    "David Marr, who joined MIT's AI Lab in 1973 and became a tenured Psychology professor by 1980, was initially focused on the general theory of the brain but shifted to the study of computer vision. \n",
    "\n",
    "He was probably the first to advocate for a computational approach to vision. [Source](https://www.turingpost.com/p/cvhistory2)\n",
    "\n",
    "### Marr's Findings:\n",
    "\n",
    "**Vision is Hierachical.**\n",
    "\n",
    "Marr proposed a representational framework for vision. He concentrated on the vision task of deriving shape information from images. [Source](https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/GOMES1/marr.html)\n",
    "\n",
    "![Marr's Framework](../img/hubel_wiesel/Marr_Framework.png)\n",
    "\n",
    "[Source - Lecture 1](https://cs231n.stanford.edu/slides/2016/)\n",
    "\n",
    "Recommended Read:\n",
    "\n",
    "[The Dawn of Computer Vision: From Concept to Early Models (1950-70s)](https://www.turingpost.com/p/cvhistory2)\n",
    "\n",
    "[Marr's Theory](https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/GOMES1/marr.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we make computers understand Vision? ü§®\n",
    "\n",
    "First, why? Why bother?\n",
    "\n",
    "If we can bridge the semantic gap, we as humans can solve more complex problems.\n",
    "\n",
    "Images are just a result of digital cameras, so what we have is just bunch of numbers.\n",
    "\n",
    "![Images For Computers](../img/hubel_wiesel/images_for_computers.png)\n",
    "\n",
    "[Source](https://www.researchgate.net/publication/327436958_Automatic_Virus_Identification_using_TEM_-_Image_Segmentation_and_Texture_Analysis)\n",
    "\n",
    "We are trying to make computers understand/interpret the world, similar to how we do.\n",
    "\n",
    "So that's the semantic gap we are trying to bridge.\n",
    "\n",
    "- All the physical products we use are a result of an production line.\n",
    "\n",
    "- Every production line can be improved and people can get goods for cheaper.\n",
    "\n",
    "- Quality checking is done with help of Computer Vision.\n",
    "\n",
    "Here are some of the problems that are solved with help of Computer Vision:\n",
    "\n",
    "![DHL Report](../img/hubel_wiesel/dhlReport.png)\n",
    "\n",
    "[Source](https://www.dhl.com/us-en/microsites/csi/computer-vision/understanding-computer-vision.html)\n",
    "\n",
    "### Recommended Read:\n",
    "\n",
    "[Computer Vision on Manufacturing](https://www.itransition.com/computer-vision/manufacturing)\n",
    "\n",
    "[Vehicle Inspection Systems](https://www.assemblymag.com/articles/96075-ai-based-vision-technology-aids-vehicle-inspection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Recognition üß†\n",
    "\n",
    "**Recognition**: localization of all the items present in the image.\n",
    "\n",
    "To make primitive computer to understand the visual structure, it has to be reduced to **simple structures**.\n",
    "\n",
    "Here is a wonderful paper about different approaches:\n",
    "\n",
    "![The Paper](../img/hubel_wiesel/recognition_history_paper.png)\n",
    "\n",
    "Here is a list of categories in all of the different approaches:\n",
    "\n",
    "![Approaches](../img/hubel_wiesel/approaches_categorized.png)\n",
    "\n",
    "We will go over 2 of them.\n",
    "\n",
    "- Brooks & Binford, 1979, Generalized Cylinder Model\n",
    "- Fischler and Elschlager, 1973, Pictorial Structure Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brooks - \n",
    "\n",
    "Rodney Brooks was a director in MIT AI Lab - he is also the founder of iRobot - the company that makes Roombas.\n",
    "\n",
    "![Roomba](../img/hubel_wiesel/Roomba_805.jpg)\n",
    "\n",
    "Brooks biggest idea was: **\"World is combined of simple shapes\"**.\n",
    "\n",
    "The distinguishing characteristic of Brooks‚Äô work is that it is one of the first systems having used parts-based recognition and generalized cylinders to provide reliable results. [Source](https://www.researchgate.net/publication/257484936_50_Years_of_object_recognition_Directions_forward)\n",
    "\n",
    "A generalized cylinder is a solid object that is formed by moving a 2D shape along a 3D curve. \n",
    "\n",
    "It's like a cylinder, but the shape that's being moved can be any 2D shape, not just a circle, and the curve it's moved along can be any 3D curve, not just a straight line. \n",
    "\n",
    "This allows for a wide variety of shapes to be described using this concept, from simple cylinders to more complex biological and manufactured objects.\n",
    "\n",
    "![Brooks Generalized Cyclinders](../img/hubel_wiesel/brooks_generalized_cyclinders.png)\n",
    "\n",
    "There is a video about three research projects completed in 1972 at the Stanford Artificial Intelligence Lab.\n",
    "\n",
    "This video is a great example how generalized-cylinder representation is used.\n",
    "\n",
    "[Video - Motion & Vision (1972)](https://www.youtube.com/watch?v=laWnTCg5I9w)\n",
    "\n",
    "Recommended Read:\n",
    "\n",
    "- [History of Computer Vision](https://letsdatascience.com/learn/history/history-of-computer-vision/)\n",
    "- [50 Years of object recognition: Directions forward](https://www.researchgate.net/publication/257484936_50_Years_of_object_recognition_Directions_forward)\n",
    "- [Generalized Cylinder Representation](https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/OWENS/LECT13/node4.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fischler - \n",
    "\n",
    "Brooks approach was about modeling the world with simple shapes.\n",
    "\n",
    "There is also a **parts and structure** approach.\n",
    "\n",
    "![Parts and Structure](../img/hubel_wiesel/fischler_et_al.png)\n",
    "\n",
    "In simple terms, it's a method to break down an object into its basic components, like:\n",
    "\n",
    "- Axes: The main lines or directions that make up the object's shape.\n",
    "- Sides: The flat surfaces that connect the axes.\n",
    "- Vertices: The points where the axes and sides meet.\n",
    "\n",
    "Think of it like building with blocks: the axes are the main beams, the sides are the flat surfaces, and the vertices are the corners where they all come together.\n",
    "\n",
    "![The Paper](../img/hubel_wiesel/fischler.png)\n",
    "\n",
    "Fischler and Elschlager's Pictorial Structure Model has had a significant impact on our understanding of visual perception and has influenced various fields.\n",
    "\n",
    "In Computer vision, the model has inspired the development of algorithms for image segmentation, object recognition, and scene understanding.\n",
    "\n",
    "### Recommended Reads:\n",
    "\n",
    "- [Fischler Paper](https://web.archive.org/web/20180413104022id_/http://people.csail.mit.edu:80/torralba/courses/6.870/papers/fischler_1973.pdf)\n",
    "- [MIT 6.870 Lecture 1](https://www.slideshare.net/zukun/mit6870-grounding-object-recognition-and-scene-understanding-lecture-1)\n",
    "- [MIT 6.870 All Lectures](https://people.csail.mit.edu/torralba/courses/6.870_2011f/6.870.grounding.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary üòå\n",
    "\n",
    "- In this video, we learned about the early research on the visual cortex.\n",
    "\n",
    "- We gained insight into how vision occurs in the brain.\n",
    "\n",
    "- We understood the beginnings of Computer Vision and the motivation for trying to fill the semantic gap.\n",
    "\n",
    "- We realized that in order to recognize an image and in this sense understand the visual structure on the computer, it needs to be reduced to **simple structures**, and we examined two solutions to this problem.\n",
    "\n",
    "- In the following video, we will examine the legendary articles of computer vision that have stood the test of time and develop sample applications.\n",
    "\n",
    "- See you in the next video!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
